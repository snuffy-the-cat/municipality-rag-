# Municipality RAG - Environment Variables Template
# Copy this file to .env and fill in your actual values

# ============================================================================
# LLM API KEYS (Optional - only needed if not using Ollama)
# ============================================================================

# OpenAI API Key
# Get from: https://platform.openai.com/api-keys
# Only needed if using OpenAI models instead of Ollama
OPENAI_API_KEY=sk-your-key-here

# Anthropic API Key
# Get from: https://console.anthropic.com/
# Only needed if using Claude models
ANTHROPIC_API_KEY=sk-ant-your-key-here

# ============================================================================
# RAG SYSTEM CONFIGURATION
# ============================================================================

# Which LLM backend to use: ollama | openai | anthropic
LLM_BACKEND=ollama

# Model name (depends on backend)
# Ollama: llama3.1, mistral, phi3, etc.
# OpenAI: gpt-3.5-turbo, gpt-4, etc.
# Anthropic: claude-3-haiku-20240307, claude-3-sonnet-20240229, etc.
LLM_MODEL=llama3.1

# Ollama API URL (if running locally)
OLLAMA_BASE_URL=http://localhost:11434

# ============================================================================
# EMBEDDING CONFIGURATION
# ============================================================================

# Embedding provider: openai | ollama
EMBEDDING_BACKEND=openai

# Embedding model
# OpenAI: text-embedding-3-small, text-embedding-3-large
# Ollama: nomic-embed-text, mxbai-embed-large
EMBEDDING_MODEL=text-embedding-3-small

# ============================================================================
# VECTOR DATABASE
# ============================================================================

# ChromaDB directory
CHROMA_DB_DIR=./database/chroma_db

# Collection name
CHROMA_COLLECTION=municipal_knowledge

# ============================================================================
# DOCUMENT GENERATION
# ============================================================================

# Output directory for generated documents
OUTPUT_DIR=./data/generated/markdown

# Batch size (how many documents to generate at once)
BATCH_SIZE=5

# ============================================================================
# LOGGING
# ============================================================================

# Log level: DEBUG | INFO | WARNING | ERROR
LOG_LEVEL=INFO

# Log directory
LOG_DIR=./outputs/logs

# ============================================================================
# ADVANCED SETTINGS
# ============================================================================

# Chunk size for document splitting
CHUNK_SIZE=1000

# Chunk overlap
CHUNK_OVERLAP=200

# Number of chunks to retrieve for each query
RETRIEVAL_K=5

# LLM temperature (0.0 = deterministic, 1.0 = creative)
LLM_TEMPERATURE=0.7

# Max tokens for LLM response
MAX_TOKENS=4000
