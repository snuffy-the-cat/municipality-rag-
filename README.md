# Municipality Knowledge Transfer System - RAG

A RAG (Retrieval-Augmented Generation) system for capturing and querying municipal employee knowledge during transitions.

---

## ğŸ¯ Project Goal

Build a system where departing municipal employees document their responsibilities in a structured format, and new employees can query this knowledge base using natural language questions in Hebrew.

---

## ğŸ—ï¸ System Architecture - 3 Stages

```
Stage 1: DATA CREATION
    Input files (.md) â†’ Generated via LLM (POC) OR Real employee input (Production)
    â†“
Stage 2: DATA PROCESSING
    Raw .md â†’ YAML fixes â†’ Validation â†’ Chunking â†’ Vector DB
    â†“
Stage 3: DATA QUERYING
    User question â†’ Semantic search â†’ LLM synthesis â†’ Answer with sources
```

---

## ğŸ“ Project Structure

```
municipality-rag/
â”‚
â”œâ”€â”€ config/                          # Global configuration
â”‚   â””â”€â”€ models_config.yaml           # LLM model settings (all stages)
â”‚
â”œâ”€â”€ 1_data_creation/                 # STAGE 1: Create input data
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ responsibility_graph.yaml          # English POC definitions
â”‚   â”‚   â””â”€â”€ responsibility_graph_hebrew.yaml   # Hebrew POC definitions
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ generate_documents.py              # Generate English docs (POC)
â”‚       â””â”€â”€ generate_documents_hebrew.py       # Generate Hebrew docs (POC)
â”‚
â”œâ”€â”€ 2_data_processing/               # STAGE 2: Process data â†’ Vector DB
â”‚   â”œâ”€â”€ core/                        # Core processing modules
â”‚   â”‚   â”œâ”€â”€ parser.py                # Extract YAML + markdown
â”‚   â”‚   â”œâ”€â”€ yaml_fixer.py            # Fix broken YAML
â”‚   â”‚   â”œâ”€â”€ chunker.py               # Split by semantic sections
â”‚   â”‚   â”œâ”€â”€ validator.py             # Validate chunks
â”‚   â”‚   â””â”€â”€ core.md                  # Module documentation
â”‚   â”œâ”€â”€ scripts/                     # Processing pipeline scripts
â”‚   â”‚   â”œâ”€â”€ preprocessing.py         # Apply YAML fixes
â”‚   â”‚   â”œâ”€â”€ validate_preprocessed.py # Verify quality
â”‚   â”‚   â”œâ”€â”€ indexing.py              # Index to ChromaDB
â”‚   â”‚   â””â”€â”€ scripts.md               # Script documentation
â”‚   â””â”€â”€ templates/                   # Validation templates
â”‚       â”œâ”€â”€ input_template_english.md
â”‚       â””â”€â”€ input_template_hebrew.md
â”‚
â”œâ”€â”€ 3_data_querying/                 # STAGE 3: Query system
â”‚   â””â”€â”€ query_system.py              # Interactive Q&A
â”‚
â”œâ”€â”€ data/                            # Data storage
â”‚   â”œâ”€â”€ raw/                         # Input .md files (before processing)
â”‚   â”œâ”€â”€ processed/                   # YAML-fixed .md files (ready for indexing)
â”‚   â””â”€â”€ generated/                   # POC-generated files (temporary)
â”‚
â”œâ”€â”€ database/                        # Vector database
â”‚   â””â”€â”€ chroma/                      # ChromaDB storage
â”‚
â”œâ”€â”€ logs/                            # System logs
â”‚   â”œâ”€â”€ indexing_*.log               # Text logs
â”‚   â””â”€â”€ indexing_*.jsonl             # Structured JSON logs
â”‚
â””â”€â”€ old/                             # One-time helpers (not continuous use)
```

---

## ğŸš€ Quick Start

### **Stage 1: Data Creation (POC)**

```bash
# Generate Hebrew documents using configured model
python 1_data_creation/scripts/generate_documents_hebrew.py

# Output: data/generated/markdown-hebrew/*.md
```

### **Stage 2: Data Processing**

```bash
# Step 1: Fix YAML in raw documents
python 2_data_processing/scripts/preprocessing.py
# Input:  data/raw/*.md
# Output: data/processed/*.md

# Step 2: Validate processed documents
python 2_data_processing/scripts/validate_preprocessed.py
# Input:  data/processed/*.md
# Output: Console report

# Step 3: Index to vector database
python 2_data_processing/scripts/indexing.py
# Input:  data/processed/*.md
# Output: database/chroma/
```

### **Stage 3: Querying**

```bash
# Interactive Q&A
python 3_data_querying/query_system.py
```

---

## ğŸ“Š Data Formats & Flow

| Stage | Input Format | Output Format | Location |
|-------|-------------|---------------|----------|
| **1. Creation** | responsibility_graph.yaml | .md with YAML frontmatter | data/generated/ |
| **2. Processing** | Raw .md files | ChromaDB vector database | database/chroma/ |
| **3. Querying** | User question (text) | Answer + sources (text) | Console/UI |

### **Data Flow:**

```
responsibility_graph_hebrew.yaml
    â†“
generate_documents_hebrew.py
    â†“
data/raw/*.md (raw input)
    â†“
preprocessing.py (YAML fixes via yaml_fixer.py)
    â†“
data/processed/*.md (clean YAML)
    â†“
validate_preprocessed.py (quality check)
    â†“
indexing.py (parser â†’ chunker â†’ validator â†’ ChromaDB)
    â†“
database/chroma/ (vector DB)
    â†“
query_system.py
    â†“
User gets answer with sources
```

---

## ğŸ”§ Configuration

### **Models Configuration** (`config/models_config.yaml`)

Choose which LLM model to use for Hebrew generation:

```yaml
active_model:
  hebrew: "qwen2.5:7b"  # Options: llama3.1, qwen2.5:7b, mistral-nemo, aya:8b
```

---

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **LLM** | Ollama (Qwen/Mistral/Aya) | Hebrew document generation |
| **Vector DB** | ChromaDB | Semantic search |
| **Embeddings** | ChromaDB default | Multilingual support |
| **Framework** | Custom pipeline | Modular processing |
| **Storage** | Markdown + YAML | Human-readable, versionable |

---

## ğŸ“– Documentation

- **2_data_processing/core/core.md** - Core module documentation (input/output)
- **2_data_processing/scripts/scripts.md** - Processing scripts documentation
- **PROJECT_STRUCTURE.md** - Detailed project structure
- **STATUS.md** - Current status and roadmap

---

## ğŸ¯ Current Status

- âœ… English system complete (30 documents)
- âœ… Hebrew models installed (Qwen, Mistral, Aya)
- ğŸ”„ Hebrew model comparison in progress (3Ã—5 documents)
- â³ Hebrew full system (15 documents) - pending
- â³ Production validation templates - pending

---

## ğŸ”® Production vs POC

### **POC (Current):**
- Documents generated by LLM from responsibility graphs
- Used for testing and development
- Located in `data/generated/`

### **Production (Future):**
- Real employee input via forms/templates
- Validated against templates in `2_data_processing/templates/`
- Stored in `data/raw/` â†’ processed â†’ indexed
- Same processing pipeline as POC

---

## ğŸ“ License

[Add your license]

---

**Note:** This is a research system for Hebrew municipal knowledge transfer.
